% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{verbatim}
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable


\parindent 0pt % Disable paragraph indent and add paragraph spacing
\parskip 6pt

\begin{document}

\bibliographystyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Oliver Lane}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{Audio Fingerprinting for Music Recongition} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
Trinity Hall \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Name:               & \bf Oliver Lane                       \\
College:            & \bf Trinity Hall                     \\
Project Title:      & \bf Audio Fingerprinting for Music Recognition \\
Examination:        & \bf Computer Science Tripos -- Part II, July 2015  \\
Word count:         & \bf   \\
Project Originator: & Oliver Lane                    \\
Supervisor:         & Vaiva Imbrasait\'{e}                    \\ 
\end{tabular}
}


\section*{Original Aims of the Project}

In this project I aimed firstly to implement at least two audio fingerprinting algorithms, each with a corresponding matching algorithm, for the purpose of recognising clips of songs from a library in a way that is robust to noise and distortions.

Secondly, I aimed to assemble a library of songs and corresponsing test clips against which to test these algorithms.

Finally, I aimed to compare these implementations against several criteria, including size of fingerprints generated and percentage of test clips matched correctly from the assembled library, at various clip lengths and levels of noise.

\section*{Work Completed}

Two implementations for audio fingerprinting algorithms were created, with corresponsing matching algorithms. These were the algorithms proposed by Avery Wang in 2003 \cite{Wang03} and Haitsma et al. in 2002 \cite{Haitsma02}. A library of songs was assembled, and corresponding test cases made by taking different length clips from the library and adding distortions.

The implementations were tested and evaluated against the test cases and each other.

\section*{Special Difficulties}

None.

 
\newpage
\section*{Declaration}

I, Oliver Lane of Trinity Hall, being a candidate for Part II of the Computer Science Tripos, hereby declare that this dissertation and the work described in  it are my own work, unaided except as may be specified below, and that the  dissertation does not contain material that has already been used to any  substantial extent for a comparable purpose.

\bigskip
\leftline{Signed}

\medskip
\leftline{Date}

\tableofcontents

\listoffigures


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\pagestyle{headings}

\chapter{Introduction}


This project concerns the implementation and comparison of two algorithms for audio fingerprinting. Each algorithms consists of a fingerprinter, which generates an audio fingerprint from a given piece of audio, and a matcher, which matches a fingerprint against a precomputed database of fingerprints for a library of known songs.

I have successfully implemented two algorithms and evaluated them against a library of over 700 songs. The algorithms have been evaluated against each other for several different criteria, including robustness to several types of audio distortion and the size of the resulting database.


\section{Background}

An audio fingerprint is a compact representation of some audio, which summarises its content. It can be thought of as a kind of hash, where the aim is that perceptually similar pieces of audio -- that is, audio which sounds the same or very similar to the human ear -- have similar hash values.

One of the principal uses of this technology is to retrieve metadata for songs based on a short clip. For example, a user might want to identify a song's name and artist by recording a clip of it from their mobile phone. Music labels might use the technology to automatically monitor radio stations to ensure the correct song royalties are being paid.

Audio fingerprinting algorithms need to work independently to the representation of the audio signal. For instance, two instances of the same song encoded at different rates of compression will have quite different representations but are very perceptually similar, and so should have similar fingerprints. As a result, the algorithms need to be robust to distortions. 

The specific distortions an algorithm tries to be robust towards are often dependent on the intended use cases, but most algorithms try to be resistant to background noise, cropping, and compression artefacts as a minimum.

There are a number of algorithms for audio fingerprinting which have been proposed in the literature, some of which have been used extensively for commercial applications. This project implements two algorithms from the literature and attempts to compare their strengths and weaknesses.


\section{Algorithms implemented}

Two algorithms were implemented for the project. The first of these is a commercially deployed algorithm developed by Avery Wang from Shazam \cite{Wang03}. The second is an algorithm proposed by Philips researchers Haitsma et al. in 2002 \cite{Haitsma02}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Preparation}

\section{Review of audio fingerprinting techniques}

The first step undertaken was to review the current literature around the area. One particularly useful paper was \textit{A review of algorithms for audio fingerprinting} \cite{Cano02}, which gives a good overview of the general structure of most audio fingerprinting algorithms. This gave me a good starting point for my system design.

I also focussed on fully understanding the two algorithms which I had considered during my proposal \cite{Haitsma02} \cite{Wang03}. Both use many of the techniques I have learnt in Part II courses, particularly from Digital Signal Processing, which meant I was well placed to implement them well. However, they also have interesting differences in their approaches, and so they were chosen as the two algorithms to be implemented for this project.


\section{Testing}

\subsection{Library}

To test the audio fingerprinting algorithms, a reasonably large library of songs was required to match against. Both of the papers I was focussing on tested their algorithms on databases of 10,000 songs, but a library this size would be difficult for me to obtain for this project. A library size of at least 500 songs was decided, as a compromise between time constraints and the quality of the testing.

Ideally, the library would also need to be fairly diverse in terms of song genres and styles, in order to reduce biases in the testing process. 

My own local music library was used as the basis for my test set (around 600 songs). Luckily I have a fairly diverse music taste, but I also supplemented the library with more songs from the Free Music Archive to increase the representation of less common genres in my local collection. The full test library consists of 720 songs.

\subsection{Test types}

Testing the algorithms consists of inputting clips of known songs in the library, and recording whether each clip was matched to the correct song. Different distortions are applied to these clips so as to test the algorithms' resilience to different types of distortions in the input signal.


- Decided on types of tests


\section{Technology choice}

- Learnt MATLAB
- Database stuff, MIRToolbox


\section{System design}

- Planned structure of code


\section{Starting point}

- Existing stuff used (see starting point in proposal)


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Implementation}

- remember to include thoughts about testing at this point

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Evaluation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusion}

In this project I successfully implemented two algorithms for audio fingerprinting and demonstrated their use for song recognition. I gathered a library of songs to test against, and used it to evaluate and compare both algorithms against a variety of criteria.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix


\chapter{Project Proposal}

\input{proposal}

\end{document}
