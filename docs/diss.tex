
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{verbatim}
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable


\parindent 0pt % Disable paragraph indent and add paragraph spacing
\parskip 6pt

\begin{document}

\bibliographystyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Oliver Lane}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{Audio Fingerprinting for Music Recongition} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
Trinity Hall \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Name:               & \bf Oliver Lane                       \\
College:            & \bf Trinity Hall                     \\
Project Title:      & \bf Audio Fingerprinting for Music Recognition \\
Examination:        & \bf Computer Science Tripos -- Part II, July 2015  \\
Word count:         & \bf   \\
Project Originator: & Oliver Lane                    \\
Supervisor:         & Vaiva Imbrasait\'{e}                    \\ 
\end{tabular}
}


\section*{Original Aims of the Project}

In this project I aimed firstly to implement at least two audio fingerprinting algorithms, each with a corresponding matching algorithm, for the purpose of recognising clips of songs from a library in a way that is robust to noise and distortions.

Secondly, I aimed to assemble a library of songs and corresponsing test clips against which to test these algorithms.

Finally, I aimed to compare these implementations against several criteria, including size of fingerprints generated and percentage of test clips matched correctly from the assembled library, at various clip lengths and levels of noise.

\section*{Work Completed}

Two implementations for audio fingerprinting algorithms were created, with corresponsing matching algorithms. These algorithms were proposed by Avery Wang in 2003 \cite{Wang03} and Haitsma et al. in 2002 \cite{Haitsma02}. A library of songs was assembled, and corresponding test cases made by taking different length clips from the library and adding distortions.

The two implementations were tested and evaluated against the test cases and each other.

\section*{Special Difficulties}

None.

 
\newpage
\section*{Declaration}

I, Oliver Lane of Trinity Hall, being a candidate for Part II of the Computer Science Tripos, hereby declare that this dissertation and the work described in  it are my own work, unaided except as may be specified below, and that the  dissertation does not contain material that has already been used to any  substantial extent for a comparable purpose.

\bigskip
\leftline{Signed}

\medskip
\leftline{Date}

\tableofcontents

\listoffigures


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                              CHAPTERS

\pagestyle{headings}

\chapter{Introduction}


This project concerns the implementation and comparison of two algorithms for audio fingerprinting. Each algorithms consists of a fingerprinter, which generates an audio fingerprint from a given piece of audio, and a matcher, which matches a fingerprint against a precomputed database of fingerprints for a library of known songs.

Two algorithms were successfully implemented and evaluated against a library of over 700 songs. The algorithms were evaluated against each other for several different criteria, including robustness to several types of audio distortion and the size of the resulting database.


\section{Background}

An audio fingerprint is a compact representation of some audio, which summarises its content. It can be thought of as a kind of hash, where the aim is that perceptually similar pieces of audio -- that is, audio which sounds the same or very similar to the human ear -- have similar hash values.

One of the principal uses of this technology is to retrieve metadata for songs based on a short clip. For example, a user might want to identify a song's name and artist by recording a clip of it from their mobile phone. Music labels might use the technology to automatically monitor radio stations to ensure the correct song royalties are being paid.

Audio fingerprinting algorithms need to work independently to the representation of the audio signal. For instance, two instances of the same song encoded at different rates of compression will have quite different representations but are very perceptually similar, and so should have similar fingerprints. As a result, the algorithms need to be robust to distortions. 

The specific distortions an algorithm tries to be robust towards are often dependent on the intended use cases, but most algorithms try to be resistant to background noise, cropping, and compression artefacts as a minimum.

There are a number of algorithms for audio fingerprinting which have been proposed in the literature, some of which have been used extensively for commercial applications. This project implements two algorithms from the literature and attempts to compare their strengths and weaknesses.


\section{Algorithms implemented}

Two algorithms were implemented for the project. The first of these is a commercially deployed algorithm developed by Avery Wang from Shazam \cite{Wang03}. The second is an algorithm proposed by Philips researchers Haitsma et al. in 2002 \cite{Haitsma02}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Preparation}

This section will summarise the work that was done before implementation of any code began. Broadly, this encompasses research on the literature around the topic, learning of new skills to be used during implementation, and planning of the implementation and evaluation portions of the project.


\section{Review of audio fingerprinting techniques}

The first step undertaken was to review the current literature around the area. One particularly useful review was given by Cano et al. \cite{Cano02}, which gives a good overview of the general structure of most audio fingerprinting algorithms. This gave me a good starting point for my system design.

I also focussed on fully understanding the two algorithms which I had considered during my proposal \cite{Haitsma02} \cite{Wang03}. Both use many of the techniques I have learnt in Part II courses, particularly from Digital Signal Processing, which meant I was well placed to implement them well. However, they also have interesting differences in their approaches, and so they were chosen as the two algorithms to be implemented for this project.


\section{Evaluation}

\subsection{Library}

To test the audio fingerprinting algorithms, a reasonably large library of songs was required to match against. Both of the papers I was focussing on tested their algorithms on databases of 10,000 songs, but a library this size would be difficult for me to obtain for this project. A library size of at least 500 songs was decided, as a compromise between time constraints and the quality of the testing.

Genre and style diversity in the song library was also an important consideration, in order to reduce biases in the testing process.

My own local music library was used as the basis for my test set (around 600 songs). Fortunately my library is fairly diverse, but I also supplemented the library with more songs from the Free Music Archive to increase the representation of less common genres in my local collection. The full test library consists of 720 songs.

\subsection{Test types}

Testing the algorithms consists of inputting clips of known songs in the library, and recording whether each clip was matched to the correct song. Different distortions are applied to these clips so as to test the algorithms' resilience to different types of distortions in the input signal.

Three main categories of test clips were chosen, which are summarised below.

\subsubsection{Plain clips}

Plain clips are simply generated by cropping original song audio files to the required length, and are used as a first check during development to make sure the algorithm is functioning at a basic level. The match rate for these should be 100\%.

\subsubsection{Clips with added noise}

Clips with added noise are generated by taking plain clips and overlaying noise at different signal to noise ratios. The noise added might be generated, such as gaussian noise, or taken from a pre-recorded noise file. An example of pre-recorded noise might be a clip of ambient noise in a busy restaurant.

\subsubsection{Re-recorded clips}

Finally, a re-recorded clip is generated by playing a plain clip out of some speakers and re-recording the audio through a microphone. This captures more naturalistic distortions such as echo and reverb, as well as any inaccuracies, frequency biases or clipping introduced by the microphone or speakers.


\section{Software engineering principles}

\subsection{Technology choices}

One of my early focusses was deciding on the technologies to be used for the project. My main considerations when making these decisions were ease of development, ease of evaluation, and my own familiarity.

To make development as easy as possible, I decided to make sure there was strong library support for operations which would be useful but could take a disproportionate amount of time to implement well myself, such as audio file manipulation. For example, a fast and accurate Discrete Fourier Transform implementation was essential.

I investigated several toolkits for music information retrieval, including in particular the C++ library OpenSMILE \cite{Eyben10} and the MATLAB library MIRToolbox \cite{Lartillot07}.

Ease of evaluation was also important. Although there wouldn't be much difference in writing test scripts in most programming languages, some languages, such as MATLAB, provide inbuilt support for plotting graphs, which could speed up my workflow significantly.

I was already somewhat familiar with MATLAB, having written a little for the Part 1A NST Mathematics course, and for various exercises in Part 1B. I was also familiar with C++ through the Part 1B course. However, I would not have described myself as experienced with either language.

On balance, I decided that MATLAB was the better choice, mainly on the merit of its strong inbuilt library support for both graph output and common signal processing operations. The toolkits for the two language appeared to be roughly comparable for my needs.


\subsection{Technology familiarisation}

\subsubsection{MATLAB}

Since I had limited experience using MATLAB, particularly for larger programs, I began by re-familiarising myself with the language. I did this mainly by working through small textbook-style exercises -- for example, implementing bubble sort -- and reading documentation for areas of the language I hadn't previously been exposed to such as namespacing, first-class functions and anonymous functions.

\subsubsection{MIRToolbox}

I also familiarised myself with MIRToolbox and its documentation. I started to investigate how useful it would be by importing some audio from an mp3 file and drawing a spectrogram of it. I implemented this task both with and without MIRToolbox, to compare the perfromance and ease of development. I found that the MIRToolbox version of the code was both slower and harder to develop, in that MIRToolbox tends to constrain you to a particular data flow to optimise certain operations, which makes it less flexible.

After consulting the operations available in the MATLAB standard library, I decided it would probably be possible to implement the algorithms just as easily without the use of MIRToolbox. Since, based on my preliminary tests, the MIRToolbox code might also be slower, I decided not to use MIRToolbox for my implementations.

\subsubsection{Database access}

Early on, I identified database access as a possible difficulty with my algorithm implementations. To ensure this would not be a problem, I decided to finish my familiarisation period by setting up a small database and making sure I could read and write to it.

Although MATLAB has an official Database Toolbox for database access, it is not included under the University's blanket license, so I investigated alternatives before attempting to obtain a license by other means.

I found an open source MATLAB SQLite3 driver \cite{Yamaguchi14} which worked well, and supported the full SQLite feature set, including batching multiple operations into transactions. After reading and writing to a small test database, I decided to use this database system for both my algorithm implementations.


\subsection{Version control}

Git was used as my version control system during development and writeup. This provided a backup of all code via GitHub, as well as the ability to roll back changes and develop new features on separate branches. The commit history was also very useful as a supplement to my written notes when writing up the project.


\subsection{Backup strategy}

Development was carried out on my laptop. Regular full disk backups of the machine were taken using Time Machine onto an external drive, in case of corruption or malfunction. In addition, in case of theft or loss of both the laptop and hard drive, all data was backed up remotely. This was achieved using Google Drive for the music library, and a private GitHub repository for code and documentation.


\subsection{Development strategy}



%TODO? \section{Starting point}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Implementation}

\section{System design}

- Planned structure of code




- remember to include thoughts about testing at some point

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Evaluation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusion}

In this project I successfully implemented two algorithms for audio fingerprinting and demonstrated their use for song recognition. I gathered a library of songs to test against, and used it to evaluate and compare both algorithms against a variety of criteria.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix


\chapter{Project Proposal}

\input{proposal}

\end{document}
